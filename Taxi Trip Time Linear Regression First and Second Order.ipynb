{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f623c9f7-e26a-41ee-955e-14d74b3fadb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier value: 13991.284778457406\noutliers removed = 22\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import math\n",
    "import datetime\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD, LabeledPoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def squaredError(label, prediction):\n",
    "    return (label-prediction)*(label-prediction)\n",
    "\n",
    "def calcRMSE(labelsAndPreds):\n",
    "    sqrSum = labelsAndPreds.map(lambda s: squaredError(s[0],s[1])).sum()\n",
    "    return math.sqrt(sqrSum/labelsAndPreds.count())\n",
    "\n",
    "def normalizeFeatures(lp):\n",
    "    normalizedFeatures = list()\n",
    "    for i in range(0,len(lp.features)):\n",
    "        feature = (lp.features[i]-broadcastMean.value[i])/broadcastStdev.value[i]\n",
    "        if not np.isnan(float(feature)):\n",
    "            normalizedFeatures.insert(i,feature)\n",
    "        else: #handle NaN's\n",
    "            normalizedFeatures.insert(i,0)\n",
    "    return LabeledPoint(lp.label, normalizedFeatures)\n",
    "\n",
    "def getNormalizedRDD(nonNormalizedRDD): \n",
    "    meanList = list()\n",
    "    stdevList = list()\n",
    "    numFeatures = len(nonNormalizedRDD.take(1)[0].features)\n",
    "    for i in range(0,numFeatures):\n",
    "        featureRDD = nonNormalizedRDD.map(lambda lp: lp.features[i])\n",
    "        featureMean = featureRDD.mean()\n",
    "        featureStdev = featureRDD.stdev()\n",
    "        meanList.insert(i,featureMean)\n",
    "        stdevList.insert(i,featureStdev)\n",
    "    global broadcastMean \n",
    "    broadcastMean = sc.broadcast(meanList)\n",
    "    global broadcastStdev \n",
    "    broadcastStdev = sc.broadcast(stdevList)\n",
    "    returnRDD = nonNormalizedRDD.map(normalizeFeatures)\n",
    "    return returnRDD\n",
    "\n",
    "def getDistance(lat1, long1, lat2, long2):\n",
    "    pickup = [float(lat1), float(long1)]\n",
    "    dropoff = [float(lat2), float(long2)]\n",
    "    pickupInRadians = [math.radians(_) for _ in pickup]\n",
    "    dropOffInRadians = [math.radians(_) for _ in dropoff]\n",
    "    result = haversine_distances([pickupInRadians, dropOffInRadians])\n",
    "    return result[0][1] * 6371000/1000\n",
    "\n",
    "def dateTimeToTuple(dateTime):\n",
    "    date = datetime.datetime.strptime(dateTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return (date.year, date.month, date.day, date.hour, date.minute)\n",
    "\n",
    "\n",
    "def timeToPeriodOneHot(inputHour):\n",
    "    hour = int(inputHour)\n",
    "    if hour >= 0 and hour < 6:          # overnight\n",
    "        return [1,0,0,0]\n",
    "    elif hour >= 6 and hour < 12:       # morning\n",
    "        return [0,1,0,0]\n",
    "    elif hour >= 12 and hour < 18:      # afternoon\n",
    "        return [0,0,1,0]\n",
    "    elif hour >= 18 and hour <= 24:     # evening\n",
    "        return [0,0,0,1]\n",
    "    else:\n",
    "        return [0,0,0,0]\n",
    "\n",
    "def weekdayOrWeekendOneHot(datetimeToCheck):\n",
    "    dayNum = datetime.datetime.strptime(datetimeToCheck, \"%Y-%m-%d %H:%M:%S\").weekday()\n",
    "    if dayNum < 5:                      # weekday\n",
    "        return [1,0]\n",
    "    elif dayNum == 5 or dayNum == 6:    # weekend\n",
    "        return [0,1]\n",
    "    else:\n",
    "        return [0,0]\n",
    "   \n",
    "def monthToSeasonOneHot(monthToCheck):\n",
    "    month = int(monthToCheck)\n",
    "\n",
    "    if month == 12 or month == 1 or month == 2:     # winter\n",
    "        return [1,0,0,0]\n",
    "    elif month > 2 and month <= 5:                  # spring\n",
    "        return [0,1,0,0]\n",
    "    elif month > 5 and month <= 8:                  # summer\n",
    "        return [0,0,1,0]\n",
    "    elif month > 8 and month <= 11:                 # fall\n",
    "        return [0,0,0,1]\n",
    "    else:\n",
    "        return [0,0,0,0]\n",
    "\n",
    "\n",
    "def extractFields(taxiTripRDD):\n",
    "    fields = taxiTripRDD.split(',')\n",
    "    vendor_id = fields[1]\n",
    "    pickup_datetime = fields[2]\n",
    "    passenger_count = fields[4]\n",
    "    store_and_fwd_flag = 0 if fields[9] == 'N' else 1\n",
    "    trip_duration = fields[10]\n",
    "\n",
    "    pickup_longitude = fields[5]\n",
    "    pickup_latitude = fields[6]\n",
    "    dropoff_longitude = fields[7]\n",
    "    dropoff_latitude = fields[8]\n",
    "\n",
    "    distance_traveled = getDistance(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)\n",
    "\n",
    "    dateTuple = dateTimeToTuple(pickup_datetime)\n",
    "\n",
    "    pickup_year = dateTuple[0]\n",
    "    pickup_season = monthToSeasonOneHot(dateTuple[1])\n",
    "    pickup_day_type = weekdayOrWeekendOneHot(pickup_datetime)\n",
    "    pickup_period_of_day = timeToPeriodOneHot(dateTuple[3])\n",
    "    \n",
    "    return (int(trip_duration), \n",
    "            (int(vendor_id), \n",
    "             store_and_fwd_flag, \n",
    "             int(passenger_count), \n",
    "             pickup_season[0],              #isWinter\n",
    "             pickup_season[1],              #isSpring\n",
    "             pickup_season[2],              #isSummer\n",
    "             pickup_season[3],              #isFall\n",
    "             pickup_day_type[0],            #isWeekday\n",
    "             pickup_day_type[1],            #isWeekend\n",
    "             pickup_period_of_day[0],       #isOvernight\n",
    "             pickup_period_of_day[1],       #isMorning\n",
    "             pickup_period_of_day[2],       #isAfternoon\n",
    "             pickup_period_of_day[3],       #isNight\n",
    "             round(distance_traveled, 5)))\n",
    "\n",
    "def parsePoint(line):\n",
    "    return LabeledPoint(line[0], line[1])\n",
    "\n",
    "def transformFeaturesToSecondOrder(RDDPair):\n",
    "    secondOrderFeatures = list(RDDPair.features)\n",
    "    for feature in RDDPair.features:\n",
    "        secondOrderFeatures.append(feature*feature)\n",
    "\n",
    "    return LabeledPoint(RDDPair.label, tuple(secondOrderFeatures))\n",
    "\n",
    "\n",
    "dataRDDwithHeader = sc.textFile(\"dbfs:/FileStore/shared_uploads/luke.couture@ucalgary.ca/train.csv\")\n",
    "\n",
    "# Filter out header row with feature names\n",
    "header = dataRDDwithHeader.first()\n",
    "dataRDD = dataRDDwithHeader.filter(lambda row: row != header)\n",
    "\n",
    "# Take 1% of data\n",
    "truncatedRDD = dataRDD.sample(False, 0.01, 17)\n",
    "\n",
    "# Extract Relevant Fields and transform to LabeledPoint\n",
    "extractedDataRDD = truncatedRDD.map(extractFields)\n",
    "parsedPointsRDD = extractedDataRDD.map(parsePoint)\n",
    "\n",
    "# predict outlier value based on 4 * sd\n",
    "sd_y = np.std(parsedPointsRDD.map(lambda l: int(l.label)).collect())\n",
    "mean_y = np.mean(parsedPointsRDD.map(lambda l: int(l.label)).collect())\n",
    "outlier_value = mean_y + (4 * sd_y)\n",
    "print(f'outlier value: {outlier_value}')\n",
    "\n",
    "# remove any values greater than outlier value\n",
    "truncatedRDDNoOutliers = parsedPointsRDD.filter(lambda x: x.label < outlier_value)\n",
    "print(f'outliers removed = {parsedPointsRDD.count()-truncatedRDDNoOutliers.count()}')\n",
    "\n",
    "# Normalize first order RDD\n",
    "normalizedParsedPointsRDD = getNormalizedRDD(truncatedRDDNoOutliers)\n",
    "\n",
    "# Create second order RDD and normalize\n",
    "truncatedRDDNoOutliersSecondOrder = truncatedRDDNoOutliers.map(transformFeaturesToSecondOrder)\n",
    "normalizedParsedPointsRDDSecondOrder = getNormalizedRDD(truncatedRDDNoOutliersSecondOrder)\n",
    "\n",
    "\n",
    "# split training and validation data\n",
    "weights = [.8, .2] # train/test split\n",
    "seed = 17\n",
    "parsedTrainData, parsedValData = normalizedParsedPointsRDD.randomSplit(weights,seed)\n",
    "parsedTrainData.cache()\n",
    "parsedValData.cache()\n",
    "parsedTrainDataSecondOrder, parsedValDataSecondOrder = normalizedParsedPointsRDDSecondOrder.randomSplit(weights,seed)\n",
    "parsedTrainDataSecondOrder.cache()\n",
    "parsedValDataSecondOrder.cache()\n",
    "\n",
    "# Values to use when training the linear regression model\n",
    "numIters = 500  # iterations\n",
    "alpha = 1  # step\n",
    "miniBatchFrac = 1.0  # miniBatchFraction\n",
    "reg = 1e-1  # regParam\n",
    "regType = 'l2'  # regType\n",
    "useIntercept = True  # intercept\n",
    "\n",
    "# create first degree linear regression model\n",
    "firstModel = LinearRegressionWithSGD.train(parsedTrainData,numIters,alpha,miniBatchFrac,initialWeights=None,regParam=reg,regType=regType,intercept=useIntercept)\n",
    "\n",
    "# create second degree linear regression model\n",
    "secondModel = LinearRegressionWithSGD.train(parsedTrainDataSecondOrder,numIters,alpha,miniBatchFrac,initialWeights=None,regParam=reg,regType=regType,intercept=useIntercept)\n",
    "\n",
    "# calculate baseline RMSE (using average as a guess for each trip's duration) for training and validation data\n",
    "averageTripDuration2 = (parsedTrainData.map(lambda trip: trip.label)).mean()\n",
    "labelsAndPredsTrain = parsedTrainData.map(lambda trip: (trip.label,averageTripDuration))\n",
    "rmseTrainBase = calcRMSE(labelsAndPredsTrain)\n",
    "labelsAndPredsVal = parsedValData.map(lambda trip: (trip.label,averageTripDuration))\n",
    "rmseValBase = calcRMSE(labelsAndPredsVal)\n",
    "print('Baseline Train RMSE = {0:.3f}'.format(rmseTrainBase))\n",
    "print('Baseline Validation RMSE = {0:.3f}'.format(rmseValBase))\n",
    "\n",
    "###################################################################################################################\n",
    "#                                                                                                                 #\n",
    "#                                   First Order Model Results                                                     #\n",
    "#                                                                                                                 #\n",
    "###################################################################################################################\n",
    "\n",
    "# calculate RMSE for predictions\n",
    "labelsAndPreds = parsedValData.map(lambda lp: (lp.label,firstModel.predict(lp.features)))\n",
    "\n",
    "# calculate RMSE for training validation\n",
    "labelsAndPredsTrain1 = parsedTrainData.map(lambda lp: (lp.label,firstModel.predict(lp.features)))\n",
    "\n",
    "rmseValLR1 = calcRMSE(labelsAndPreds)\n",
    "rmseTrainLR1 = calcRMSE(labelsAndPredsTrain1)\n",
    "print('Prediction RMSE 1st Order = {0:.3f}'.format(rmseValLR1))\n",
    "print('Training RMSE 1st Order = {0:.3f}'.format(rmseTrainLR1))\n",
    "\n",
    "predictions = labelsAndPreds.map(lambda labelAndPred: labelAndPred[1]).collect()\n",
    "yVals = parsedValData.map(lambda lp: lp.label).collect()\n",
    "xVals = parsedValData.map(lambda lp: lp.features[-1]).collect()\n",
    "\n",
    "\n",
    "plt.scatter(xVals, yVals, color='blue', label='Actual')\n",
    "plt.scatter(xVals, predictions, color='red', label='Predicted')\n",
    "plt.xlabel('Distance Traveled')\n",
    "plt.ylabel('Trip Times')\n",
    "plt.title('Taxi Trip Time Prediction using First Order Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "#                                                                                                                 #\n",
    "#                                   Second Order Model Results                                                    #\n",
    "#                                                                                                                 #\n",
    "###################################################################################################################\n",
    "\n",
    "# calculate RMSE for predictions\n",
    "labelsAndPreds2 = parsedValDataSecondOrder.map(lambda lp: (lp.label,secondModel.predict(lp.features)))\n",
    "\n",
    "# calculate RMSE for training validation\n",
    "labelsAndPredsTrain2 = parsedTrainDataSecondOrder.map(lambda lp: (lp.label,secondModel.predict(lp.features)))\n",
    "\n",
    "rmseValLR2 = calcRMSE(labelsAndPreds2)\n",
    "rmseTrainLR2 = calcRMSE(labelsAndPredsTrain2)\n",
    "print('Prediction RMSE 2nd Order = {0:.3f}'.format(rmseValLR2))\n",
    "print('Training RMSE 2nd Order = {0:.3f}'.format(rmseTrainLR2))\n",
    "\n",
    "predictions2 = labelsAndPreds2.map(lambda labelAndPred: labelAndPred[1]).collect()\n",
    "\n",
    "plt.scatter(xVals, yVals, color='blue', label='Actual')\n",
    "plt.scatter(xVals, predictions2, color='red', label='Predicted')\n",
    "plt.xlabel('Distance Traveled')\n",
    "plt.ylabel('Trip Times')\n",
    "plt.title('Taxi Trip Time Prediction using Second Order Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Taxi Trip Time Linear Regression First and Second Order",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
